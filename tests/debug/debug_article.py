import asyncio
import aiohttp
from bs4 import BeautifulSoup
from rich.console import Console
from rich.panel import Panel

console = Console()

async def debug_article_page():
    """ì¡°ì„ ì¼ë³´ ê°œë³„ ê¸°ì‚¬ í˜ì´ì§€ HTML êµ¬ì¡° ë¶„ì„"""
    
    # ì‹¤ì œ ê¸°ì‚¬ URL (ë””ë²„ê·¸ ê²°ê³¼ì—ì„œ ê°€ì ¸ì˜¨ ê²ƒ)
    article_url = "https://www.chosun.com/politics/politics_general/2025/08/20/HXC43KR5LVH2XAG5XMMSHWXFJY/"
    
    async with aiohttp.ClientSession() as session:
        try:
            async with session.get(article_url, headers={
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }) as response:
                
                if response.status != 200:
                    console.print(f"[red]ì ‘ê·¼ ì‹¤íŒ¨: {response.status}[/red]")
                    return
                
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                console.print(Panel(f"ğŸ” ê¸°ì‚¬ í˜ì´ì§€ ë¶„ì„: {article_url}", border_style="blue"))
                
                # 1. ì œëª© ì°¾ê¸°
                console.print("\n[cyan]ğŸ“ ì œëª© ì°¾ê¸°:[/cyan]")
                title_selectors = [
                    'h1', 'h2', 'h3', 'h4', 
                    '.title', '.headline', '.article-title',
                    '.story-headline', '.headline-text',
                    '[data-testid="headline"]',
                    'title'
                ]
                
                for selector in title_selectors:
                    elements = soup.select(selector)
                    if elements:
                        console.print(f"[green]âœ… {selector}: {len(elements)}ê°œ ë°œê²¬[/green]")
                        for elem in elements[:2]:
                            text = elem.get_text(strip=True)
                            if text:
                                console.print(f"   - {text[:100]}...")
                    else:
                        console.print(f"[red]âŒ {selector}: ì—†ìŒ[/red]")
                
                # 2. ë³¸ë¬¸ ì°¾ê¸°
                console.print("\n[cyan]ğŸ“„ ë³¸ë¬¸ ì°¾ê¸°:[/cyan]")
                content_selectors = [
                    '.content', '.body', '.article-content', '.article-body',
                    '.text', '.story-content', '.article-text',
                    '.content-text', '.story-body',
                    'article', '.main-content'
                ]
                
                for selector in content_selectors:
                    elements = soup.select(selector)
                    if elements:
                        console.print(f"[green]âœ… {selector}: {len(elements)}ê°œ ë°œê²¬[/green]")
                        for elem in elements[:2]:
                            text = elem.get_text(strip=True)
                            if text:
                                console.print(f"   - {text[:150]}...")
                    else:
                        console.print(f"[red]âŒ {selector}: ì—†ìŒ[/red]")
                
                # 3. ì‹œê°„ ì°¾ê¸°
                console.print("\n[cyan]â° ì‹œê°„ ì°¾ê¸°:[/cyan]")
                time_selectors = [
                    '.time', '.date', '.published-time', '.article-time',
                    '.story-time', '.timestamp', '.publish-date',
                    'time', '.upDate', '.story-date'
                ]
                
                for selector in time_selectors:
                    elements = soup.select(selector)
                    if elements:
                        console.print(f"[green]âœ… {selector}: {len(elements)}ê°œ ë°œê²¬[/green]")
                        for elem in elements[:3]:
                            text = elem.get_text(strip=True)
                            if text:
                                console.print(f"   - {text}")
                    else:
                        console.print(f"[red]âŒ {selector}: ì—†ìŒ[/red]")
                
                # 4. ê¸°ìëª… ì°¾ê¸°
                console.print("\n[cyan]âœï¸ ê¸°ìëª… ì°¾ê¸°:[/cyan]")
                author_selectors = [
                    '.author', '.reporter', '.byline', '.writer',
                    '.story-author', '.article-author', '.by-line'
                ]
                
                for selector in author_selectors:
                    elements = soup.select(selector)
                    if elements:
                        console.print(f"[green]âœ… {selector}: {len(elements)}ê°œ ë°œê²¬[/green]")
                        for elem in elements[:3]:
                            text = elem.get_text(strip=True)
                            if text:
                                console.print(f"   - {text}")
                    else:
                        console.print(f"[red]âŒ {selector}: ì—†ìŒ[/red]")
                
                # 5. ëª¨ë“  í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ìš”ì†Œ ì°¾ê¸° (ê¸´ í…ìŠ¤íŠ¸)
                console.print("\n[cyan]ğŸ” ê¸´ í…ìŠ¤íŠ¸ ìš”ì†Œ ì°¾ê¸°:[/cyan]")
                all_elements = soup.find_all(['div', 'p', 'span', 'article', 'section'])
                
                long_text_elements = []
                for elem in all_elements:
                    text = elem.get_text(strip=True)
                    if len(text) > 200:  # 200ì ì´ìƒ
                        long_text_elements.append((elem.name, elem.get('class', []), text[:100]))
                
                console.print(f"[green]ê¸´ í…ìŠ¤íŠ¸ ìš”ì†Œ {len(long_text_elements)}ê°œ ë°œê²¬[/green]")
                for i, (tag, classes, text) in enumerate(long_text_elements[:5], 1):
                    console.print(f"{i}. {tag} {classes}: {text}...")
                
                # 6. HTML êµ¬ì¡° ì €ì¥
                with open('chosun_article_debug.html', 'w', encoding='utf-8') as f:
                    f.write(html)
                console.print(f"\n[green]ğŸ’¾ ê¸°ì‚¬ HTMLì´ 'chosun_article_debug.html'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.[/green]")
                
        except Exception as e:
            console.print(f"[red]ì—ëŸ¬ ë°œìƒ: {str(e)}[/red]")

if __name__ == "__main__":
    asyncio.run(debug_article_page())
